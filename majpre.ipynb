{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM0j2E/QcQPmkp/fF3qL6O9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ASHIKalip/object_detection/blob/main/majpre.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZLOmM0FQGu62"
      },
      "outputs": [],
      "source": [
        "%config IPCompleter.greedy=True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <br><center><img src='https://raw.githubusercontent.com/dropcreations/FFmpeg-for-Google-Colab/1bd5d8aeb88c8f402a9aea4846fab6304e7d8e43/Google-Drive-Logo.svg' height=\"50\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h3><b>Mount Google Drive</b></h3></center><br>\n",
        "MODE = \"MOUNT\" #@param [\"MOUNT\", \"UNMOUNT\"]\n",
        "#Mount your Gdrive! \n",
        "from google.colab import drive\n",
        "drive.mount._DEBUG = False\n",
        "if MODE == \"MOUNT\":\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "elif MODE == \"UNMOUNT\":\n",
        "  try:\n",
        "    drive.flush_and_unmount()\n",
        "  except ValueError:\n",
        "    pass\n",
        "  get_ipython().system_raw(\"rm -rf /root/.config/Google/DriveFS\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJUqDkmoHfCK",
        "outputId": "2ba76ed8-9dd0-4458-b702-3938bb36611b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <br><center><img src='https://raw.githubusercontent.com/dropcreations/FFmpeg-for-Google-Colab/32abf44ff4c8d145a94a24611f01141926a8daaa/FFmpeg-Logo.svg' height=\"40\" alt=\"FFmpeg-logo\"/></center>\n",
        "#@markdown <center><h3><b>Install FFmpeg</b></h3></center><br>\n",
        "from IPython.display import clear_output\n",
        "!sudo curl -L https://github.com/BtbN/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-linux64-gpl.tar.xz -o /usr/local/bin/ffmpeg.tar.xz\n",
        "clear_output()\n",
        "%cd /usr/local/bin/\n",
        "clear_output()\n",
        "!7z e /usr/local/bin/ffmpeg.tar.xz\n",
        "clear_output()\n",
        "!7z e /usr/local/bin/ffmpeg.tar\n",
        "clear_output()\n",
        "!sudo chmod a+rx /usr/local/bin/ffmpeg\n",
        "clear_output()\n",
        "%cd /content/\n",
        "!sudo curl -L https://mkvtoolnix.download/appimage/MKVToolNix_GUI-70.0.0-x86_64.AppImage -o /usr/local/bin/MKVToolNix_GUI-70.0.0-x86_64.AppImage\n",
        "!sudo chmod u+rx /usr/local/bin/MKVToolNix_GUI-70.0.0-x86_64.AppImage\n",
        "!sudo ln -s /usr/local/bin/MKVToolNix_GUI-70.0.0-x86_64.AppImage /usr/local/bin/mkvmerge\n",
        "!sudo chmod a+rx /usr/local/bin/mkvmerge\n",
        "clear_output()\n",
        "print(\"Successfully Installed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP_fk3uGItHP",
        "outputId": "6f04a753-7390-4d8a-c9b7-c123fc5bb9e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0^C\n",
            "ln: failed to create symbolic link '/usr/local/bin/mkvmerge': File exists\n",
            "Successfully Installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdhuvgyeKKWa",
        "outputId": "4e5e89b4-c7a9-4aca-e197-d5cbf5202ef9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6084 sha256=086ad689c5ec569664bb5d573ef5f52a2a25447470ca36b891a8bc6bb074cb8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/80/6e/caa3e16deb0267c3cbfd36862058a724144e19fdb9eb03af0f\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ffmpeg as ff\n",
        "import os\n",
        "from typing import List, Tuple, Dict\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "import pickle\n",
        "import datetime"
      ],
      "metadata": {
        "id": "uOom3xx2G966"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_audio_from_video(file_path: str) -> np.ndarray:\n",
        "    inputfile = ff.input(file_path)\n",
        "    out = inputfile.output('-', format='f32le', acodec='pcm_f32le', ac=1, ar='44100')\n",
        "    raw = out.run(capture_stdout=True)\n",
        "    del inputfile, out\n",
        "    return np.frombuffer(raw[0],np.float32)\n",
        "# import os\n",
        "# import json\n",
        "# import subprocess\n",
        "# import prettytable\n",
        "\n",
        "# inputFile = \"/content/drive/MyDrive/Big5/train/0ObEtA6Q8vU.005.mp4\" #@param {type:\"string\"}\n",
        "# saveToSourceLocation = True #@param {type:\"boolean\"}\n",
        "\n",
        "# jsonFFprobe = subprocess.check_output([\n",
        "#     'ffprobe',\n",
        "#     '-hide_banner',\n",
        "#     '-loglevel',\n",
        "#     'warning',\n",
        "#     '-print_format',\n",
        "#     'json',\n",
        "#     '-show_entries',\n",
        "#     'stream',\n",
        "#     '-i',\n",
        "#     os.path.abspath(inputFile),\n",
        "#     ], stderr=subprocess.DEVNULL)\n",
        "# jsonData = json.loads(jsonFFprobe)\n",
        "\n",
        "# streamCount = len(jsonData['streams'])\n",
        "# commandLine = '-hide_banner -i \"' + inputFile + '\" '\n",
        "\n",
        "# codecTable = prettytable.PrettyTable()\n",
        "# codecTable.field_names = ['Track ID', 'Codec name', 'Channels', 'Sample rate']\n",
        "# codecTable.align = 'l'\n",
        "\n",
        "# for i in range(streamCount):\n",
        "#     codec_type = jsonData.get('streams')[int(i)].get('codec_type')\n",
        "#     if codec_type == \"audio\":\n",
        "#         index = jsonData.get('streams')[int(i)].get('index')\n",
        "#         codec_name = jsonData.get('streams')[int(i)].get('codec_name')\n",
        "#         channel_layout = jsonData.get('streams')[int(i)].get('channels')\n",
        "#         sample_rate = jsonData.get('streams')[int(i)].get('sample_rate')\n",
        "#         codecTable.add_row([index, codec_name, channel_layout, sample_rate])\n",
        "\n",
        "# stringTable = '\\t' + codecTable.__str__().replace('\\n', '\\n\\t')\n",
        "# print(stringTable)\n",
        "\n",
        "# trackID = input(\"\\ntrackID: \")\n",
        "# codec_name = jsonData.get('streams')[int(trackID)].get('codec_name')\n",
        "# if \"opus\" in codec_name:\n",
        "#     codec_ext = \"ogg\"\n",
        "# elif \"dts\" in codec_name:\n",
        "#     codec_ext = \"mka\"\n",
        "# elif \"aac\" in codec_name:\n",
        "#     codec_ext = \"aac\"\n",
        "# elif \"truehd\" in codec_name:\n",
        "#     codec_ext = \"mka\"\n",
        "# elif codec_name == \"ac3\":\n",
        "#     codec_ext = \"ac3\"\n",
        "# elif codec_name == \"eac3\":\n",
        "#     codec_ext = \"eac3\"\n",
        "# elif \"pcm\" in codec_name:\n",
        "#     codec_ext = \"wav\"\n",
        "# elif \"flac\" in codec_name:\n",
        "#     codec_ext = \"flac\"\n",
        "\n",
        "# commandLine = commandLine + \"-vn -sn -map 0:\" + str(trackID) + \" -c copy \"\n",
        "\n",
        "# sourceName = os.path.splitext(os.path.basename(os.path.abspath(inputFile)))[0]\n",
        "# sourceFolder = os.path.dirname(os.path.abspath(inputFile))\n",
        "\n",
        "# if saveToSourceLocation is True:\n",
        "#     outputFile = os.path.join(sourceFolder, (sourceName + f'_[{codec_name}].' + codec_ext))\n",
        "#     commandLine = commandLine + '\"' + outputFile + '\"'\n",
        "# else:\n",
        "#     outputFolder = input(\"outputFolder: \")\n",
        "#     outputFile = os.path.join(outputFolder, (sourceName + f'_[{codec_name}].' + codec_ext))\n",
        "#     commandLine = commandLine + '\"' + outputFile + '\"'\n",
        "\n",
        "# !ffmpeg {commandLine}"
      ],
      "metadata": {
        "id": "yvUW0AHgIqgq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_audio_series(raw_data: np.ndarray) -> np.ndarray:\n",
        "    N, M = 24, 1319\n",
        "    mfcc_data = librosa.feature.mfcc(raw_data, n_mfcc= 24)\n",
        "    \n",
        "    #Getting spectral mean (centroid)\n",
        "    #mean = librosa.feature.spectral_centroid(result)\n",
        "    \n",
        "    #Standardizing MFCC (zero mean and unit variance)\n",
        "    mfcc_data_standardized = (mfcc_data - np.mean(mfcc_data)) / np.std(mfcc_data)\n",
        "    \n",
        "    # Use pre-padding (Note: with 0, which is also the mean after standardization) to unify the length of the samples.\n",
        "    number_of_columns_to_fill = M - mfcc_data_standardized.shape[1]\n",
        "    padding = np.zeros((N,number_of_columns_to_fill))\n",
        "    \n",
        "    padded_data = np.hstack((padding, mfcc_data_standardized))\n",
        "    \n",
        "    #Reshaping to N,M,1\n",
        "    return padded_data.reshape(N,M,1)\n",
        "    "
      ],
      "metadata": {
        "id": "ygzAOphrHDTG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_number_of_frames(file_path: str) -> int:\n",
        "    probe = ff.probe(filePath)\n",
        "    video_streams = [stream for stream in probe[\"streams\"] if stream[\"codec_type\"] == \"video\"]\n",
        "    #width = video_streams[0]['coded_width']\n",
        "    #height = video_streams[0]['coded_height']\n",
        "    del probe\n",
        "    return video_streams[0]['nb_frames']"
      ],
      "metadata": {
        "id": "7uLCq4xRKbgp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_N_video_frames(file_path: str, number_of_samples: int = 6) -> List[np.ndarray]:\n",
        "    nb_frames = int(get_number_of_frames(file_path= filePath))\n",
        "    \n",
        "    video_frames = []\n",
        "    random_indexes = random.sample(range(0, nb_frames), number_of_samples)\n",
        "    \n",
        "    cap = cv2.VideoCapture(filePath)\n",
        "    for ind in random_indexes:\n",
        "        cap.set(1,ind)\n",
        "        res, frame = cap.read()\n",
        "        video_frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "    cap.release()\n",
        "    del cap, random_indexes\n",
        "    return video_frames"
      ],
      "metadata": {
        "id": "5hosnlrBKgXO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_image(image: np.ndarray, new_size: Tuple[int,int]) -> np.ndarray:\n",
        "    return cv2.resize(image, new_size, interpolation = cv2.INTER_AREA)"
      ],
      "metadata": {
        "id": "IdAlqfYqKnvh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_image_window(image: np.ndarray, training: bool = True) -> np.ndarray:\n",
        "    height, width, _ = image.shape\n",
        "    if training:\n",
        "        MAX_N = height - 128\n",
        "        MAX_M = width - 128\n",
        "        rand_N_index, rand_M_index = random.randint(0, MAX_N) , random.randint(0, MAX_M)\n",
        "        return image[rand_N_index:(rand_N_index+128),rand_M_index:(rand_M_index+128),:]\n",
        "    else:\n",
        "        N_index = (height - 128) // 2\n",
        "        M_index = (width - 128) // 2\n",
        "        return image[N_index:(N_index+128),M_index:(M_index+128),:]"
      ],
      "metadata": {
        "id": "mcG1jtfXKrTZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reading_label_data(file_name: str, dictionary: Dict[str,str]) -> np.ndarray:\n",
        "    features = ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'openness']\n",
        "    extracted_data = [float(dictionary[label][file_name]) for label in features]\n",
        "    return np.stack(extracted_data).reshape(5,1)"
      ],
      "metadata": {
        "id": "QGfXfyG6Kvd_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_input(file_path: str, file_name: str, dictionary: Dict[str,str], training: bool = True) -> Tuple[np.ndarray,np.ndarray,np.ndarray]:\n",
        "    #Audio\n",
        "    #extracted_audio_raw = extract_audio_from_video(file_path= filePath)\n",
        "    #preprocessed_audio = preprocess_audio_series(raw_data= extracted_audio_raw)\n",
        "    \n",
        "    #Video\n",
        "    # sampled = extract_N_video_frames(file_path= filePath, number_of_samples= 6)\n",
        "    # resized_images = [resize_image(image= im, new_size= (248,140)) for im in sampled]\n",
        "    # cropped_images = [crop_image_window(image= resi,training= training) / 255.0 for resi in resized_images]\n",
        "    # preprocessed_video = np.stack(cropped_images)\n",
        "    \n",
        "    #Ground Truth\n",
        "    video_gt = reading_label_data(file_name= file_name, dictionary= dictionary)\n",
        "    #del extracted_audio_raw, sampled, resized_images, cropped_images\n",
        "    #return (preprocessed_audio, preprocessed_video, video_gt)\n",
        "    return video_gt"
      ],
      "metadata": {
        "id": "t5ol4BP1Kzhj"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set_data = []\n",
        "path = '/content/drive/MyDrive/Big5/train'\n",
        "gt = pickle.load( open( \"/content/drive/MyDrive/Big5/gt/annotation_training.pkl\", \"rb\" ), encoding='latin1' )\n",
        "t1 = datetime.datetime.utcnow()\n",
        "#for filename in os.listdir(path):\n",
        "filePath = '/content/drive/MyDrive/Big5/train/0ObEtA6Q8vU.005.mp4'\n",
        "training_set_data.append(preprocessing_input(file_path= filePath, file_name= '0ObEtA6Q8vU.005.mp4', dictionary= gt, training= True))\n",
        "t2 = datetime.datetime.utcnow()\n",
        "#Measuring execution time\n",
        "print('Elapsed time: ' + str(t2-t1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IrAHvKhK5G6",
        "outputId": "8ce94a64-8061-4556-d460-58699f7115b3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 0:00:00.000406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "savename = 'training_set.dat'\n",
        "with open(savename, \"wb\") as f:\n",
        "    pickle.dump(training_set_data, f)"
      ],
      "metadata": {
        "id": "LglOhTbbLEmn"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set_data = []\n",
        "path = 'Big5/test'\n",
        "gt = pickle.load( open( \"Big5/gt/annotation_test.pkl\", \"rb\" ), encoding='latin1' )\n",
        "t1 = datetime.datetime.utcnow()\n",
        "for filename in os.listdir(path):\n",
        "    filePath = path+'/'+filename\n",
        "    test_set_data.append(preprocessing_input(file_path= filePath, file_name= filename, dictionary= gt, training= False))\n",
        "t2 = datetime.datetime.utcnow()\n",
        "#Measuring execution time\n",
        "print('Elapsed time: ' + str(t2-t1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "O8gGqxpEa9d9",
        "outputId": "16657ae2-89b5-44aa-d80f-997eb203cd00"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8e867d053438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Big5/test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"Big5/gt/annotation_test.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "savename = 'test_set.dat'\n",
        "with open(savename, \"wb\") as f:\n",
        "    pickle.dump(test_set_data, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "pJdMiDJbDNMB",
        "outputId": "0120e118-8620-47b8-db79-5146d36c173c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-dcdf2d797f86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msavename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test_set.dat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('training_set.dat', \"rb\") as training_file:\n",
        "    train_set_data = pickle.load(training_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "qQU97Gi9DV9a",
        "outputId": "cfe06c38-02f7-48c8-c397-bd8e4cb0138e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-85af6dfee17e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training_set.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training_set.dat'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('validation_set.dat', \"rb\") as validation_file:\n",
        "    validation_set_data = pickle.load(validation_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "SNls0yLoDZ5m",
        "outputId": "5f025e4a-d3cb-46ee-eede-e38dcb174ad5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-105f0d8b9ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'validation_set.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvalidation_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mvalidation_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'validation_set.dat'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test_set.dat', \"rb\") as test_file:\n",
        "    test_set_data = pickle.load(test_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "FivRrTfTDdmP",
        "outputId": "30b906ea-d695-4d9c-846f-e222bea4ebb1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ad41f657153f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_set.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtest_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gt = pickle.load( open( \"Big5/gt/annotation_training.pkl\", \"rb\" ), encoding='latin1' )\n",
        "neuroticism = list(gt['neuroticism'].values())\n",
        "extraversion = list(gt['extraversion'].values())\n",
        "agreeableness = list(gt['agreeableness'].values())\n",
        "conscientiousness = list(gt['conscientiousness'].values())\n",
        "openness = list(gt['openness'].values())\n",
        "\n",
        "df = pd.DataFrame({'neuroticism': neuroticism,'extraversion': extraversion,'agreeableness':agreeableness,'conscientiousness':conscientiousness,'openness':openness})\n",
        "df.plot(kind='density',xlim=(0,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "7CuGlKG_Dgo9",
        "outputId": "7a28c669-3db0-4fc3-e78d-2153be18f6b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c7d3b3ef418b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"Big5/gt/annotation_training.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mneuroticism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neuroticism'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mextraversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'extraversion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0magreeableness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'agreeableness'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconscientiousness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conscientiousness'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_set_data))\n",
        "print(len(validation_set_data))\n",
        "print(len(test_set_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "l39eIeqXDkLI",
        "outputId": "f4b67eae-acdc-4df7-cce9-0911c9b9d335"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6f81d9df911f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_set_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_set_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_random_index = random.randint(0, len(train_set_data)-1)\n",
        "validation_random_index = random.randint(0, len(validation_set_data)-1)\n",
        "test_random_index = random.randint(0, len(test_set_data)-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "emr4OAesDqIU",
        "outputId": "7f8062c1-309f-46bb-ee5e-20f44751f95f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-13243a36600f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_random_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalidation_random_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_set_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_random_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shape = train_set_data[train_random_index][0].shape\n",
        "mfcc_train = train_set_data[train_random_index][0].reshape(shape[0],shape[1])\n",
        "\n",
        "shape = validation_set_data[validation_random_index][0].shape\n",
        "mfcc_validation = validation_set_data[validation_random_index][0].reshape(shape[0],shape[1])\n",
        "\n",
        "shape = test_set_data[test_random_index][0].shape\n",
        "mfcc_train = test_set_data[test_random_index][0].reshape(shape[0],shape[1])\n",
        "\n",
        "mfccs = [mfcc_train,mfcc_validation,mfcc_train]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "1GbdL1FNDtxv",
        "outputId": "91ba014c-e988-466f-9b25-5c2bb305fcf0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2888053b4d89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_random_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmfcc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_random_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_set_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_random_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmfcc_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_set_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_random_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_set_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_to_plot = []\n",
        "images_to_plot.extend([(train_set_data[train_random_index][1])[i,:,:,:] for i in range(0,6)])\n",
        "images_to_plot.extend([(validation_set_data[validation_random_index][1])[i,:,:,:] for i in range(0,6)])\n",
        "images_to_plot.extend([(test_set_data[test_random_index][1])[i,:,:,:] for i in range(0,6)])\n",
        "    \n",
        "\n",
        "plt.figure(figsize=(18,11))\n",
        "\n",
        "for i in range(18):\n",
        "    plt.subplot(3,6,i+1)\n",
        "    plt.imshow(images_to_plot[i])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "H9GlI8Z2Dw2C",
        "outputId": "d8d38f82-04c4-4863-9de2-36b5f957f745"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5b723de3295f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimages_to_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimages_to_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_random_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimages_to_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_set_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_random_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimages_to_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_random_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-5b723de3295f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimages_to_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimages_to_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_random_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimages_to_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_set_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_random_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimages_to_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_random_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_set_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "librosa.display.specshow(mfccs[0], x_axis='time', y_axis='mel')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "NgddQdf1D0aH",
        "outputId": "ffb939c2-dd02-4777-bff6-e56627240c02"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e179f55f689b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfccs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'librosa' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "43K-8oa3D6_a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}